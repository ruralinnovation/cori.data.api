{"version":3,"file":"cori.data.api518.js","sources":["../../node_modules/apache-arrow/ipc/writer.mjs"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { __asyncValues, __awaiter } from \"tslib\";\nimport { Table } from '../table.mjs';\nimport { MAGIC } from './message.mjs';\nimport { Vector } from '../vector.mjs';\nimport { DataType } from '../type.mjs';\nimport { Message } from './metadata/message.mjs';\nimport * as metadata from './metadata/message.mjs';\nimport { FileBlock, Footer } from './metadata/file.mjs';\nimport { MessageHeader, MetadataVersion } from '../enum.mjs';\nimport { compareSchemas } from '../visitor/typecomparator.mjs';\nimport { AsyncByteQueue } from '../io/stream.mjs';\nimport { VectorAssembler } from '../visitor/vectorassembler.mjs';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler.mjs';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler.mjs';\nimport { toUint8Array } from '../util/buffer.mjs';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch.mjs';\nimport { ReadableInterop } from '../io/interfaces.mjs';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat.mjs';\nexport class RecordBatchWriter extends ReadableInterop {\n    /** @nocollapse */\n    // @ts-ignore\n    static throughNode(options) {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    static throughDOM(\n    // @ts-ignore\n    writableStrategy, \n    // @ts-ignore\n    readableStrategy) {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n    constructor(options) {\n        super();\n        this._position = 0;\n        this._started = false;\n        // @ts-ignore\n        this._sink = new AsyncByteQueue();\n        this._schema = null;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n    toString(sync = false) {\n        return this._sink.toString(sync);\n    }\n    toUint8Array(sync = false) {\n        return this._sink.toUint8Array(sync);\n    }\n    writeAll(input) {\n        if (isPromise(input)) {\n            return input.then((x) => this.writeAll(x));\n        }\n        else if (isAsyncIterable(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, input);\n    }\n    get closed() { return this._sink.closed; }\n    [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    toDOMStream(options) { return this._sink.toDOMStream(options); }\n    toNodeStream(options) { return this._sink.toNodeStream(options); }\n    close() {\n        return this.reset()._sink.close();\n    }\n    abort(reason) {\n        return this.reset()._sink.abort(reason);\n    }\n    finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    reset(sink = this._sink, schema = null) {\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink;\n        }\n        else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            }\n            else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n        if (!schema || !(compareSchemas(schema, this._schema))) {\n            if (schema == null) {\n                this._position = 0;\n                this._schema = null;\n            }\n            else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n        return this;\n    }\n    write(payload) {\n        let schema = null;\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        }\n        else if (payload == null) {\n            return this.finish() && undefined;\n        }\n        else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n        else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n        if (schema && !compareSchemas(schema, this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        }\n        else if (payload instanceof Table) {\n            this.writeAll(payload.batches);\n        }\n        else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n    _writeMessage(message, alignment = 8) {\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n        else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) {\n            this._write(buffer);\n        }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n    _write(chunk) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n    _writeSchema(schema) {\n        return this._writeMessage(Message.from(schema));\n    }\n    // @ts-ignore\n    _writeFooter(schema) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n    _writeMagic() {\n        return this._write(MAGIC);\n    }\n    _writePadding(nBytes) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n    _writeRecordBatch(batch) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.numRows, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n    _writeDictionaryBatch(dictionary, id, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(new Vector([dictionary]));\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n    _writeBodyBuffers(buffers) {\n        let buffer;\n        let size, padding;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n    _writeDictionaries(batch) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary === null || dictionary === void 0 ? void 0 : dictionary.slice(offset)).length > 0) {\n                for (const data of dictionary.data) {\n                    this._writeDictionaryBatch(data, id, offset > 0);\n                    offset += data.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n/** @ignore */\nexport class RecordBatchStreamWriter extends RecordBatchWriter {\n    /** @nocollapse */\n    static writeAll(input, options) {\n        const writer = new RecordBatchStreamWriter(options);\n        if (isPromise(input)) {\n            return input.then((x) => writer.writeAll(x));\n        }\n        else if (isAsyncIterable(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n/** @ignore */\nexport class RecordBatchFileWriter extends RecordBatchWriter {\n    /** @nocollapse */\n    static writeAll(input) {\n        const writer = new RecordBatchFileWriter();\n        if (isPromise(input)) {\n            return input.then((x) => writer.writeAll(x));\n        }\n        else if (isAsyncIterable(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n    // @ts-ignore\n    _writeSchema(schema) {\n        return this._writeMagic()._writePadding(2);\n    }\n    _writeFooter(schema) {\n        const buffer = Footer.encode(new Footer(schema, MetadataVersion.V5, this._recordBatchBlocks, this._dictionaryBlocks));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n/** @ignore */\nexport class RecordBatchJSONWriter extends RecordBatchWriter {\n    /** @nocollapse */\n    static writeAll(input) {\n        return new RecordBatchJSONWriter().writeAll(input);\n    }\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n    _writeMessage() { return this; }\n    // @ts-ignore\n    _writeFooter(schema) { return this; }\n    _writeSchema(schema) {\n        return this._write(`{\\n  \"schema\": ${JSON.stringify({ fields: schema.fields.map(field => fieldToJSON(field)) }, null, 2)}`);\n    }\n    _writeDictionaries(batch) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    _writeDictionaryBatch(dictionary, id, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(dictionaryBatchToJSON(dictionary, id, isDelta));\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    _writeRecordBatch(batch) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    close() {\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(recordBatchToJSON(this._recordBatches[i]));\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n        this._dictionaries = [];\n        this._recordBatches = [];\n        return super.close();\n    }\n}\n/** @ignore */\nfunction writeAll(writer, input) {\n    let chunks = input;\n    if (input instanceof Table) {\n        chunks = input.batches;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n/** @ignore */\nfunction writeAllAsync(writer, batches) {\n    var _a, batches_1, batches_1_1;\n    var _b, e_1, _c, _d;\n    return __awaiter(this, void 0, void 0, function* () {\n        try {\n            for (_a = true, batches_1 = __asyncValues(batches); batches_1_1 = yield batches_1.next(), _b = batches_1_1.done, !_b; _a = true) {\n                _d = batches_1_1.value;\n                _a = false;\n                const batch = _d;\n                writer.write(batch);\n            }\n        }\n        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n        finally {\n            try {\n                if (!_a && !_b && (_c = batches_1.return)) yield _c.call(batches_1);\n            }\n            finally { if (e_1) throw e_1.error; }\n        }\n        return writer.finish();\n    });\n}\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }) {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map((field) => fieldToJSON(field)),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary, id, isDelta = false) {\n    const [columns] = JSONVectorAssembler.assemble(new RecordBatch({ [id]: dictionary }));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n/** @ignore */\nfunction recordBatchToJSON(records) {\n    const [columns] = JSONVectorAssembler.assemble(records);\n    return JSON.stringify({\n        'count': records.numRows,\n        'columns': columns\n    }, null, 2);\n}\n\n//# sourceMappingURL=writer.mjs.map\n"],"names":["RecordBatchWriter","ReadableInterop","options","writableStrategy","readableStrategy","AsyncByteQueue","isObject","sync","input","isPromise","x","isAsyncIterable","writeAllAsync","writeAll","reason","sink","schema","isWritableDOMStream","isWritableNodeStream","compareSchemas","payload","Table","RecordBatch","_InternalEmptyPlaceholderRecordBatch","isIterable","message","alignment","a","buffer","Message","flatbufferSize","prefixSize","alignedSize","nPaddingBytes","MessageHeader","FileBlock","chunk","toUint8Array","MAGIC","nBytes","batch","byteLength","nodes","bufferRegions","buffers","VectorAssembler","recordBatch","metadata.RecordBatch","dictionary","id","isDelta","Vector","dictionaryBatch","metadata.DictionaryBatch","size","padding","i","n","offset","data","RecordBatchStreamWriter","writer","RecordBatchFileWriter","Footer","MetadataVersion","chunks","batches","_a","batches_1","batches_1_1","_b","e_1","_c","_d","__awaiter","__asyncValues","e_1_1"],"mappings":";;;;;;;;;;;;;;;;;;;;;AAkCO,MAAMA,UAA0BC,EAAgB;AAAA;AAAA;AAAA,EAGnD,OAAO,YAAYC,GAAS;AACxB,UAAM,IAAI,MAAM,iDAAiD;AAAA,EACpE;AAAA;AAAA,EAED,OAAO,WAEPC,GAEAC,GAAkB;AACd,UAAM,IAAI,MAAM,gDAAgD;AAAA,EACnE;AAAA,EACD,YAAYF,GAAS;AACjB,aACA,KAAK,YAAY,GACjB,KAAK,WAAW,IAEhB,KAAK,QAAQ,IAAIG,KACjB,KAAK,UAAU,MACf,KAAK,oBAAoB,IACzB,KAAK,qBAAqB,IAC1B,KAAK,0BAA0B,oBAAI,OACnCC,EAASJ,CAAO,MAAMA,IAAU,EAAE,aAAa,IAAM,sBAAsB,GAAK,IAChF,KAAK,eAAgB,OAAOA,EAAQ,eAAgB,YAAaA,EAAQ,cAAc,IACvF,KAAK,wBAAyB,OAAOA,EAAQ,wBAAyB,YAAaA,EAAQ,uBAAuB;AAAA,EACrH;AAAA,EACD,SAASK,IAAO,IAAO;AACnB,WAAO,KAAK,MAAM,SAASA,CAAI;AAAA,EAClC;AAAA,EACD,aAAaA,IAAO,IAAO;AACvB,WAAO,KAAK,MAAM,aAAaA,CAAI;AAAA,EACtC;AAAA,EACD,SAASC,GAAO;AACZ,WAAIC,EAAUD,CAAK,IACRA,EAAM,KAAK,CAACE,MAAM,KAAK,SAASA,CAAC,CAAC,IAEpCC,EAAgBH,CAAK,IACnBI,EAAc,MAAMJ,CAAK,IAE7BK,EAAS,MAAML,CAAK;AAAA,EAC9B;AAAA,EACD,IAAI,SAAS;AAAE,WAAO,KAAK,MAAM;AAAA,EAAS;AAAA,EAC1C,CAAC,OAAO,aAAa,IAAI;AAAE,WAAO,KAAK,MAAM,OAAO,aAAa,EAAC;AAAA,EAAK;AAAA,EACvE,YAAYN,GAAS;AAAE,WAAO,KAAK,MAAM,YAAYA,CAAO;AAAA,EAAI;AAAA,EAChE,aAAaA,GAAS;AAAE,WAAO,KAAK,MAAM,aAAaA,CAAO;AAAA,EAAI;AAAA,EAClE,QAAQ;AACJ,WAAO,KAAK,MAAK,EAAG,MAAM,MAAK;AAAA,EAClC;AAAA,EACD,MAAMY,GAAQ;AACV,WAAO,KAAK,MAAO,EAAC,MAAM,MAAMA,CAAM;AAAA,EACzC;AAAA,EACD,SAAS;AACL,gBAAK,eAAe,KAAK,UAAU,KAAK,MAAM,KAAK,OAAO,KAAK,OAAO,GAC/D;AAAA,EACV;AAAA,EACD,MAAMC,IAAO,KAAK,OAAOC,IAAS,MAAM;AACpC,WAAKD,MAAS,KAAK,SAAWA,aAAgBV,IAC1C,KAAK,QAAQU,KAGb,KAAK,QAAQ,IAAIV,KACbU,KAAQE,EAAoBF,CAAI,IAChC,KAAK,YAAY,EAAE,MAAM,QAAO,CAAE,EAAE,OAAOA,CAAI,IAE1CA,KAAQG,EAAqBH,CAAI,KACtC,KAAK,aAAa,EAAE,YAAY,GAAK,CAAE,EAAE,KAAKA,CAAI,IAGtD,KAAK,YAAY,KAAK,WACtB,KAAK,aAAa,KAAK,OAAO,GAElC,KAAK,WAAW,IAChB,KAAK,oBAAoB,IACzB,KAAK,qBAAqB,IAC1B,KAAK,0BAA0B,oBAAI,QAC/B,CAACC,KAAU,CAAEG,EAAeH,GAAQ,KAAK,OAAO,OAC5CA,KAAU,QACV,KAAK,YAAY,GACjB,KAAK,UAAU,SAGf,KAAK,WAAW,IAChB,KAAK,UAAUA,GACf,KAAK,aAAaA,CAAM,KAGzB;AAAA,EACV;AAAA,EACD,MAAMI,GAAS;AACX,QAAIJ,IAAS;AACb,QAAK,KAAK,OAGL;AAAA,UAAII,KAAW;AAChB,eAAO,KAAK,OAAQ,KAAI;AAEvB,UAAIA,aAAmBC,KAAS,EAAEL,IAASI,EAAQ;AACpD,eAAO,KAAK,OAAQ,KAAI;AAEvB,UAAIA,aAAmBE,KAAe,EAAEN,IAASI,EAAQ;AAC1D,eAAO,KAAK,OAAQ,KAAI;AAAA;AATxB,YAAM,IAAI,MAAM,6BAA6B;AAWjD,QAAIJ,KAAU,CAACG,EAAeH,GAAQ,KAAK,OAAO,GAAG;AACjD,UAAI,KAAK,YAAY,KAAK;AACtB,eAAO,KAAK;AAEhB,WAAK,MAAM,KAAK,OAAOA,CAAM;AAAA,IAChC;AACD,IAAII,aAAmBE,IACbF,aAAmBG,KACrB,KAAK,kBAAkBH,CAAO,IAG7BA,aAAmBC,IACxB,KAAK,SAASD,EAAQ,OAAO,IAExBI,EAAWJ,CAAO,KACvB,KAAK,SAASA,CAAO;AAAA,EAE5B;AAAA,EACD,cAAcK,GAASC,IAAY,GAAG;AAClC,UAAMC,IAAID,IAAY,GAChBE,IAASC,EAAQ,OAAOJ,CAAO,GAC/BK,IAAiBF,EAAO,YACxBG,IAAc,KAAK,wBAA4B,IAAJ,GAC3CC,IAAeF,IAAiBC,IAAaJ,IAAK,CAACA,GACnDM,IAAgBD,IAAcF,IAAiBC;AACrD,WAAIN,EAAQ,eAAeS,EAAc,cACrC,KAAK,mBAAmB,KAAK,IAAIC,EAAUH,GAAaP,EAAQ,YAAY,KAAK,SAAS,CAAC,IAEtFA,EAAQ,eAAeS,EAAc,mBAC1C,KAAK,kBAAkB,KAAK,IAAIC,EAAUH,GAAaP,EAAQ,YAAY,KAAK,SAAS,CAAC,GAGzF,KAAK,yBACN,KAAK,OAAO,WAAW,GAAG,EAAE,CAAC,GAGjC,KAAK,OAAO,WAAW,GAAGO,IAAcD,CAAU,CAAC,GAE/CD,IAAiB,KACjB,KAAK,OAAOF,CAAM,GAGf,KAAK,cAAcK,CAAa;AAAA,EAC1C;AAAA,EACD,OAAOG,GAAO;AACV,QAAI,KAAK,UAAU;AACf,YAAMR,IAASS,EAAaD,CAAK;AACjC,MAAIR,KAAUA,EAAO,aAAa,MAC9B,KAAK,MAAM,MAAMA,CAAM,GACvB,KAAK,aAAaA,EAAO;AAAA,IAEhC;AACD,WAAO;AAAA,EACV;AAAA,EACD,aAAaZ,GAAQ;AACjB,WAAO,KAAK,cAAca,EAAQ,KAAKb,CAAM,CAAC;AAAA,EACjD;AAAA;AAAA,EAED,aAAaA,GAAQ;AAEjB,WAAO,KAAK,wBACN,KAAK,OAAO,WAAW,GAAG,CAAC,CAAC,IAC5B,KAAK,OAAO,WAAW,GAAG,IAAI,CAAC,CAAC;AAAA,EACzC;AAAA,EACD,cAAc;AACV,WAAO,KAAK,OAAOsB,CAAK;AAAA,EAC3B;AAAA,EACD,cAAcC,GAAQ;AAClB,WAAOA,IAAS,IAAI,KAAK,OAAO,IAAI,WAAWA,CAAM,CAAC,IAAI;AAAA,EAC7D;AAAA,EACD,kBAAkBC,GAAO;AACrB,UAAM,EAAE,YAAAC,GAAY,OAAAC,GAAO,eAAAC,GAAe,SAAAC,EAAO,IAAKC,EAAgB,SAASL,CAAK,GAC9EM,IAAc,IAAIC,EAAqBP,EAAM,SAASE,GAAOC,CAAa,GAC1ElB,IAAUI,EAAQ,KAAKiB,GAAaL,CAAU;AACpD,WAAO,KACF,mBAAmBD,CAAK,EACxB,cAAcf,CAAO,EACrB,kBAAkBmB,CAAO;AAAA,EACjC;AAAA,EACD,sBAAsBI,GAAYC,GAAIC,IAAU,IAAO;AACnD,SAAK,wBAAwB,IAAID,GAAID,EAAW,UAAU,KAAK,wBAAwB,IAAIC,CAAE,KAAK,EAAE;AACpG,UAAM,EAAE,YAAAR,GAAY,OAAAC,GAAO,eAAAC,GAAe,SAAAC,EAAS,IAAGC,EAAgB,SAAS,IAAIM,EAAO,CAACH,CAAU,CAAC,CAAC,GACjGF,IAAc,IAAIC,EAAqBC,EAAW,QAAQN,GAAOC,CAAa,GAC9ES,IAAkB,IAAIC,EAAyBP,GAAaG,GAAIC,CAAO,GACvEzB,IAAUI,EAAQ,KAAKuB,GAAiBX,CAAU;AACxD,WAAO,KACF,cAAchB,CAAO,EACrB,kBAAkBmB,CAAO;AAAA,EACjC;AAAA,EACD,kBAAkBA,GAAS;AACvB,QAAIhB,GACA0B,GAAMC;AACV,aAASC,IAAI,IAAIC,IAAIb,EAAQ,QAAQ,EAAEY,IAAIC;AACvC,OAAK7B,IAASgB,EAAQY,CAAC,OAAOF,IAAO1B,EAAO,cAAc,MACtD,KAAK,OAAOA,CAAM,IACb2B,KAAYD,IAAO,IAAK,MAAMA,KAAQ,KACvC,KAAK,cAAcC,CAAO;AAItC,WAAO;AAAA,EACV;AAAA,EACD,mBAAmBf,GAAO;AACtB,aAAS,CAACS,GAAID,CAAU,KAAKR,EAAM,cAAc;AAC7C,UAAIkB,IAAS,KAAK,wBAAwB,IAAIT,CAAE,KAAK;AACrD,UAAIS,MAAW,MAAMV,IAAaA,KAAe,OAAgC,SAASA,EAAW,MAAMU,CAAM,GAAG,SAAS;AACzH,mBAAWC,KAAQX,EAAW;AAC1B,eAAK,sBAAsBW,GAAMV,GAAIS,IAAS,CAAC,GAC/CA,KAAUC,EAAK;AAAA,IAG1B;AACD,WAAO;AAAA,EACV;AACL;AAEO,MAAMC,UAAgC5D,EAAkB;AAAA;AAAA,EAE3D,OAAO,SAASQ,GAAON,GAAS;AAC5B,UAAM2D,IAAS,IAAID,EAAwB1D,CAAO;AAClD,WAAIO,EAAUD,CAAK,IACRA,EAAM,KAAK,CAACE,MAAMmD,EAAO,SAASnD,CAAC,CAAC,IAEtCC,EAAgBH,CAAK,IACnBI,EAAciD,GAAQrD,CAAK,IAE/BK,EAASgD,GAAQrD,CAAK;AAAA,EAChC;AACL;AAEO,MAAMsD,UAA8B9D,EAAkB;AAAA;AAAA,EAEzD,OAAO,SAASQ,GAAO;AACnB,UAAMqD,IAAS,IAAIC;AACnB,WAAIrD,EAAUD,CAAK,IACRA,EAAM,KAAK,CAACE,MAAMmD,EAAO,SAASnD,CAAC,CAAC,IAEtCC,EAAgBH,CAAK,IACnBI,EAAciD,GAAQrD,CAAK,IAE/BK,EAASgD,GAAQrD,CAAK;AAAA,EAChC;AAAA,EACD,cAAc;AACV,aACA,KAAK,eAAe;AAAA,EACvB;AAAA;AAAA,EAED,aAAaQ,GAAQ;AACjB,WAAO,KAAK,YAAW,EAAG,cAAc,CAAC;AAAA,EAC5C;AAAA,EACD,aAAaA,GAAQ;AACjB,UAAMY,IAASmC,EAAO,OAAO,IAAIA,EAAO/C,GAAQgD,EAAgB,IAAI,KAAK,oBAAoB,KAAK,iBAAiB,CAAC;AACpH,WAAO,MACF,aAAahD,CAAM,EACnB,OAAOY,CAAM,EACb,OAAO,WAAW,GAAGA,EAAO,UAAU,CAAC,EACvC;EACR;AACL;AA8DA,SAASf,EAASgD,GAAQrD,GAAO;AAC7B,MAAIyD,IAASzD;AACb,EAAIA,aAAiBa,MACjB4C,IAASzD,EAAM,SACfqD,EAAO,MAAM,QAAWrD,EAAM,MAAM;AAExC,aAAWgC,KAASyB;AAChB,IAAAJ,EAAO,MAAMrB,CAAK;AAEtB,SAAOqB,EAAO;AAClB;AAEA,SAASjD,EAAciD,GAAQK,GAAS;AACpC,MAAIC,GAAIC,GAAWC,GACfC,GAAIC,GAAKC,GAAIC;AACjB,SAAOC,EAAU,MAAM,QAAQ,QAAQ,aAAa;AAChD,QAAI;AACA,WAAKP,IAAK,IAAMC,IAAYO,EAAcT,CAAO,GAAGG,IAAc,MAAMD,EAAU,KAAM,GAAEE,IAAKD,EAAY,MAAM,CAACC,GAAIH,IAAK,IAAM;AAC7H,QAAAM,IAAKJ,EAAY,OACjBF,IAAK;AACL,cAAM3B,IAAQiC;AACd,QAAAZ,EAAO,MAAMrB,CAAK;AAAA,MACrB;AAAA,IACJ,SACMoC,GAAO;AAAE,MAAAL,IAAM,EAAE,OAAOK,EAAO;AAAA,IAAG,UACjC;AACJ,UAAI;AACA,QAAI,CAACT,KAAM,CAACG,MAAOE,IAAKJ,EAAU,YAAS,MAAMI,EAAG,KAAKJ,CAAS;AAAA,MACrE,UACO;AAAE,YAAIG;AAAK,gBAAMA,EAAI;AAAA,MAAQ;AAAA,IACxC;AACD,WAAOV,EAAO;EACtB,CAAK;AACL;","x_google_ignoreList":[0]}