{"version":3,"file":"cori.data.api656.js","sources":["../../node_modules/micromark-core-commonmark/lib/content.js"],"sourcesContent":["/**\n * @typedef {import('micromark-util-types').Construct} Construct\n * @typedef {import('micromark-util-types').Resolver} Resolver\n * @typedef {import('micromark-util-types').State} State\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').TokenizeContext} TokenizeContext\n * @typedef {import('micromark-util-types').Tokenizer} Tokenizer\n */\n\nimport { factorySpace } from 'micromark-factory-space';\nimport { markdownLineEnding } from 'micromark-util-character';\nimport { subtokenize } from 'micromark-util-subtokenize';\n/**\n * No name because it must not be turned off.\n * @type {Construct}\n */\nexport const content = {\n  tokenize: tokenizeContent,\n  resolve: resolveContent\n};\n\n/** @type {Construct} */\nconst continuationConstruct = {\n  tokenize: tokenizeContinuation,\n  partial: true\n};\n\n/**\n * Content is transparent: itâ€™s parsed right now. That way, definitions are also\n * parsed right now: before text in paragraphs (specifically, media) are parsed.\n *\n * @type {Resolver}\n */\nfunction resolveContent(events) {\n  subtokenize(events);\n  return events;\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContent(effects, ok) {\n  /** @type {Token | undefined} */\n  let previous;\n  return chunkStart;\n\n  /**\n   * Before a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkStart(code) {\n    effects.enter(\"content\");\n    previous = effects.enter(\"chunkContent\", {\n      contentType: \"content\"\n    });\n    return chunkInside(code);\n  }\n\n  /**\n   * In a content chunk.\n   *\n   * ```markdown\n   * > | abc\n   *     ^^^\n   * ```\n   *\n   * @type {State}\n   */\n  function chunkInside(code) {\n    if (code === null) {\n      return contentEnd(code);\n    }\n\n    // To do: in `markdown-rs`, each line is parsed on its own, and everything\n    // is stitched together resolving.\n    if (markdownLineEnding(code)) {\n      return effects.check(continuationConstruct, contentContinue, contentEnd)(code);\n    }\n\n    // Data.\n    effects.consume(code);\n    return chunkInside;\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentEnd(code) {\n    effects.exit(\"chunkContent\");\n    effects.exit(\"content\");\n    return ok(code);\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function contentContinue(code) {\n    effects.consume(code);\n    effects.exit(\"chunkContent\");\n    previous.next = effects.enter(\"chunkContent\", {\n      contentType: \"content\",\n      previous\n    });\n    previous = previous.next;\n    return chunkInside;\n  }\n}\n\n/**\n * @this {TokenizeContext}\n * @type {Tokenizer}\n */\nfunction tokenizeContinuation(effects, ok, nok) {\n  const self = this;\n  return startLookahead;\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function startLookahead(code) {\n    effects.exit(\"chunkContent\");\n    effects.enter(\"lineEnding\");\n    effects.consume(code);\n    effects.exit(\"lineEnding\");\n    return factorySpace(effects, prefixed, \"linePrefix\");\n  }\n\n  /**\n   *\n   *\n   * @type {State}\n   */\n  function prefixed(code) {\n    if (code === null || markdownLineEnding(code)) {\n      return nok(code);\n    }\n\n    // Always populated by defaults.\n\n    const tail = self.events[self.events.length - 1];\n    if (!self.parser.constructs.disable.null.includes('codeIndented') && tail && tail[1].type === \"linePrefix\" && tail[2].sliceSerialize(tail[1], true).length >= 4) {\n      return ok(code);\n    }\n    return effects.interrupt(self.parser.constructs.flow, nok, ok)(code);\n  }\n}"],"names":["content","tokenizeContent","resolveContent","continuationConstruct","tokenizeContinuation","events","subtokenize","effects","ok","previous","chunkStart","code","chunkInside","contentEnd","markdownLineEnding","contentContinue","nok","self","startLookahead","factorySpace","prefixed","tail"],"mappings":";;;;;;;;;AAgBY,MAACA,IAAU;AAAA,EACrB,UAAUC;AAAA,EACV,SAASC;AACX,GAGMC,IAAwB;AAAA,EAC5B,UAAUC;AAAA,EACV,SAAS;AACX;AAQA,SAASF,EAAeG,GAAQ;AAC9B,SAAAC,EAAYD,CAAM,GACXA;AACT;AAMA,SAASJ,EAAgBM,GAASC,GAAI;AAEpC,MAAIC;AACJ,SAAOC;AAYP,WAASA,EAAWC,GAAM;AACxB,WAAAJ,EAAQ,MAAM,SAAS,GACvBE,IAAWF,EAAQ,MAAM,gBAAgB;AAAA,MACvC,aAAa;AAAA,IACnB,CAAK,GACMK,EAAYD,CAAI;AAAA,EACxB;AAYD,WAASC,EAAYD,GAAM;AACzB,WAAIA,MAAS,OACJE,EAAWF,CAAI,IAKpBG,EAAmBH,CAAI,IAClBJ,EAAQ,MAAMJ,GAAuBY,GAAiBF,CAAU,EAAEF,CAAI,KAI/EJ,EAAQ,QAAQI,CAAI,GACbC;AAAA,EACR;AAOD,WAASC,EAAWF,GAAM;AACxB,WAAAJ,EAAQ,KAAK,cAAc,GAC3BA,EAAQ,KAAK,SAAS,GACfC,EAAGG,CAAI;AAAA,EACf;AAOD,WAASI,EAAgBJ,GAAM;AAC7B,WAAAJ,EAAQ,QAAQI,CAAI,GACpBJ,EAAQ,KAAK,cAAc,GAC3BE,EAAS,OAAOF,EAAQ,MAAM,gBAAgB;AAAA,MAC5C,aAAa;AAAA,MACb,UAAAE;AAAA,IACN,CAAK,GACDA,IAAWA,EAAS,MACbG;AAAA,EACR;AACH;AAMA,SAASR,EAAqBG,GAASC,GAAIQ,GAAK;AAC9C,QAAMC,IAAO;AACb,SAAOC;AAOP,WAASA,EAAeP,GAAM;AAC5B,WAAAJ,EAAQ,KAAK,cAAc,GAC3BA,EAAQ,MAAM,YAAY,GAC1BA,EAAQ,QAAQI,CAAI,GACpBJ,EAAQ,KAAK,YAAY,GAClBY,EAAaZ,GAASa,GAAU,YAAY;AAAA,EACpD;AAOD,WAASA,EAAST,GAAM;AACtB,QAAIA,MAAS,QAAQG,EAAmBH,CAAI;AAC1C,aAAOK,EAAIL,CAAI;AAKjB,UAAMU,IAAOJ,EAAK,OAAOA,EAAK,OAAO,SAAS,CAAC;AAC/C,WAAI,CAACA,EAAK,OAAO,WAAW,QAAQ,KAAK,SAAS,cAAc,KAAKI,KAAQA,EAAK,CAAC,EAAE,SAAS,gBAAgBA,EAAK,CAAC,EAAE,eAAeA,EAAK,CAAC,GAAG,EAAI,EAAE,UAAU,IACrJb,EAAGG,CAAI,IAETJ,EAAQ,UAAUU,EAAK,OAAO,WAAW,MAAMD,GAAKR,CAAE,EAAEG,CAAI;AAAA,EACpE;AACH;","x_google_ignoreList":[0]}